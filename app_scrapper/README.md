# App Scraper - InterrapidÃ­simo Status Scraper

AplicaciÃ³n independiente para scraping de estados de tracking desde InterrapidÃ­simo.

## ğŸ“‹ Funcionalidad

- Scraping de estados desde portal web de InterrapidÃ­simo
- ActualizaciÃ³n de columnas STATUS TRACKING y STATUS INTERRAPIDISIMO
- Soporte sÃ­ncrono y asÃ­ncrono
- Procesamiento por rangos y batches
- Logging completo de operaciones

## ğŸš€ InstalaciÃ³n

```bash
cd app_scrapper
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
playwright install chromium
```

## âš™ï¸ ConfiguraciÃ³n

**IMPORTANTE: Esta app es completamente independiente**

1. Copiar `.env.example` a `.env` (en esta carpeta)
2. **Copiar tu `credentials.json` a esta carpeta `app_scrapper/`**
3. Ajustar `SPREADSHEET_NAME` en `.env`

```bash
# Estructura requerida:
app_scrapper/
â”œâ”€â”€ credentials.json     # â† TU ARCHIVO DE CREDENCIALES AQUÃ
â”œâ”€â”€ .env                 # â† TU CONFIGURACIÃ“N AQUÃ
â”œâ”€â”€ scraper_app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ ...
```

## ğŸ“ Uso

```bash
# Scraping sÃ­ncrono bÃ¡sico
python scraper_app.py

# Scraping asÃ­ncrono con concurrencia
python scraper_app.py --async --concurrency 5

# Procesar rango especÃ­fico
python scraper_app.py --start-row 100 --end-row 200

# Solo procesar filas sin estado
python scraper_app.py --only-empty

# Modo dry-run (simulaciÃ³n)
python scraper_app.py --dry-run --limit 10
```

## ğŸ“¦ Dependencias

- playwright: Web scraping
- gspread: Google Sheets API
- oauth2client: AutenticaciÃ³n Google
- python-dotenv: ConfiguraciÃ³n

## ğŸ”§ ParÃ¡metros

- `--start-row`: Fila inicial (default: 2)
- `--end-row`: Fila final (default: todas)
- `--limit`: LÃ­mite de filas
- `--async`: Usar scraper asÃ­ncrono
- `--concurrency`: PÃ¡ginas concurrentes (default: 3)
- `--batch-size`: TamaÃ±o de batch (default: 5000)
- `--only-empty`: Solo filas sin estado
- `--dry-run`: Simular sin escribir
